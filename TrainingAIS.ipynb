{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEun7y+pBaIi4P6ejLrpCh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matteraggi/FineTuningAI/blob/main/TrainingAIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install + Import**"
      ],
      "metadata": {
        "id": "MC_EV9IaJdGm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sO0SvMIXE7bE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7929d83a-ef49-4a55-edb3-f675f75cb357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# === Installazioni necessarie su Colab ===\n",
        "!pip install pandas numpy pyarrow torch matplotlib scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import random, os\n",
        "from pyproj import Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parametri**"
      ],
      "metadata": {
        "id": "ykH17mZnGNj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIG ---\n",
        "DATA_FILE = \"ais_preprocessed.parquet\"   # percorso nel runtime\n",
        "SEQUENCE_LEN = 60\n",
        "DELTA_T = \"1min\"\n",
        "FEATURES = [\"X\",\"Y\",\"SOG\",\"COG\",\"Heading\"]\n",
        "TARGET_IDX = [0,1]   # colonne X,Y nel FEATURES\n",
        "TEST_RATIO = 0.15\n",
        "VAL_RATIO = 0.15\n",
        "MMSI_SEED = 42\n",
        "torch.manual_seed(MMSI_SEED)\n",
        "np.random.seed(MMSI_SEED)\n",
        "random.seed(MMSI_SEED)\n",
        "\n",
        "# MODEL HP\n",
        "INPUT_SIZE = len(FEATURES)\n",
        "HIDDEN_SIZE = 64\n",
        "NUM_LAYERS = 1\n",
        "LR = 1e-3\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "EARLY_STOPPING_PATIENCE = 5\n",
        "\n",
        "# ATTACK / EVAL\n",
        "STD_X_M = None   # se calcoli fuori, assegna qui\n",
        "STD_Y_M = None\n",
        "\n",
        "# ANOMALIES\n",
        "ATTACK_ENABLE = True\n",
        "ATTACK_PROB   = 0.30\n",
        "DRIFT_METERS  = 500             # se sweep vuoto, usa questo\n",
        "DRIFT_SWEEP_METERS = [50, 200, 500, 1000, 2000]"
      ],
      "metadata": {
        "id": "hMOcjo9HGQiT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Caricamento dataset**"
      ],
      "metadata": {
        "id": "W9d994EYs753"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(DATA_FILE)\n",
        "print(\"Righe totali:\", len(df))\n",
        "\n",
        "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32616\", always_xy=True)\n",
        "xs_m, ys_m = transformer.transform(df[\"LON\"].values, df[\"LAT\"].values)\n",
        "STD_X_M = float(xs_m.std()) if STD_X_M is None else STD_X_M\n",
        "STD_Y_M = float(ys_m.std()) if STD_Y_M is None else STD_Y_M\n",
        "print(f\"STD_X_M={STD_X_M:.2f} m  STD_Y_M={STD_Y_M:.2f} m\")\n",
        "\n",
        "# --- Split per MMSI (meglio che split casuale su righe) ---\n",
        "# --- Per non mischiare le stesse navi tra train e test ---\n",
        "mmsi_list = df[\"MMSI\"].unique()\n",
        "rng = np.random.RandomState(MMSI_SEED)\n",
        "rng.shuffle(mmsi_list)\n",
        "\n",
        "n = len(mmsi_list)\n",
        "n_test = int(TEST_RATIO * n)\n",
        "n_val  = int(VAL_RATIO * n)\n",
        "\n",
        "test_mmsi = mmsi_list[:n_test]\n",
        "val_mmsi  = mmsi_list[n_test:n_test+n_val]\n",
        "train_mmsi = mmsi_list[n_test+n_val:]\n",
        "\n",
        "df_train = df[df[\"MMSI\"].isin(train_mmsi)]\n",
        "df_val   = df[df[\"MMSI\"].isin(val_mmsi)]\n",
        "df_test  = df[df[\"MMSI\"].isin(test_mmsi)]\n",
        "\n",
        "print(f\"Train navi: {len(train_mmsi)}, Val navi: {len(val_mmsi)}, Test navi: {len(test_mmsi)}\")"
      ],
      "metadata": {
        "id": "dm2V_ooTtArG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095055f8-85aa-42a6-d0ad-bad9dc264c3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Righe totali: 185749\n",
            "STD_X_M=33332.37 m  STD_Y_M=33116.34 m\n",
            "Train navi: 14, Val navi: 2, Test navi: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creazione finestre temporali per train, val e test**"
      ],
      "metadata": {
        "id": "iwIflSNHtQnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(df, seq_len=SEQUENCE_LEN, features=FEATURES):\n",
        "    Xs, ys = [], []\n",
        "    for mmsi, group in df.groupby(\"MMSI\"):\n",
        "        group = group.sort_values(\"BaseDateTime\")\n",
        "        data = group[features].values\n",
        "        for i in range(len(data) - seq_len):\n",
        "            Xs.append(data[i:i+seq_len])\n",
        "            ys.append(data[i+seq_len, :2])  # prevedi solo X,Y\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "X_train, y_train = create_sequences(df_train)\n",
        "X_val,   y_val   = create_sequences(df_val)\n",
        "X_test,  y_test  = create_sequences(df_test)\n",
        "\n",
        "print(f\"Train: {len(X_train)}  Val: {len(X_val)}  Test: {len(X_test)}\")"
      ],
      "metadata": {
        "id": "BaZukaKHtSUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4664c7ae-e968-4091-903d-7a755f292dce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 150349  Val: 12840  Test: 21480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM model (Long Short Term Memory)**"
      ],
      "metadata": {
        "id": "FG2Nw_hEtbY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrajectoryLSTM(nn.Module):\n",
        "    def __init__(self, input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, output_size=2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "model = TrajectoryLSTM()\n",
        "criterion = nn.SmoothL1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "gRgRrIbgte12"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "NsRJb4qjtjwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_tensor(a):\n",
        "    return torch.tensor(a, dtype=torch.float32)\n",
        "\n",
        "X_train_t, y_train_t = to_tensor(X_train), to_tensor(y_train)\n",
        "X_val_t, y_val_t = to_tensor(X_val), to_tensor(y_val)\n",
        "\n",
        "best_val = float('inf')\n",
        "patience = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    idx = torch.randperm(len(X_train_t))\n",
        "    for i in range(0, len(X_train_t), BATCH_SIZE):\n",
        "        batch_idx = idx[i:i+BATCH_SIZE]\n",
        "        Xb, yb = X_train_t[batch_idx], y_train_t[batch_idx]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(Xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # --- validazione ---\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_pred = model(X_val_t)\n",
        "        val_loss = criterion(val_pred, y_val_t).item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train loss: {loss.item():.6f} | Val loss: {val_loss:.6f}\")\n",
        "\n",
        "    # early stopping\n",
        "    if val_loss < best_val:\n",
        "        best_val = val_loss\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        patience = 0\n",
        "    else:\n",
        "        patience += 1\n",
        "        if patience >= EARLY_STOPPING_PATIENCE:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "# ricarica best\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))"
      ],
      "metadata": {
        "id": "aGC8Qa75tlGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f9adffa-2aac-4afe-e920-b2d746687838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train loss: 0.000050 | Val loss: 0.000100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creazione anomalie (spoofing simulato)**"
      ],
      "metadata": {
        "id": "AU7qvaGutpy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_silent_drift(X, std_x_m, meters, prob=1.0, axis=0, rng=None):\n",
        "    \"\"\"\n",
        "    X: (N, T, F) normalizzato\n",
        "    std_x_m: deviazione standard in metri della coordinata X\n",
        "    meters: shift in metri da applicare\n",
        "    prob: frazione di finestre da attaccare\n",
        "    axis: indice feature di X (0 se FEATURES[0]=='X')\n",
        "    rng: np.random.RandomState per riproducibilità\n",
        "    \"\"\"\n",
        "    rng = rng or np.random.RandomState(42)\n",
        "    drift_z = meters / std_x_m\n",
        "    X_att = X.copy()\n",
        "    N = len(X)\n",
        "    n_att = int(prob * N)\n",
        "    idx = rng.choice(N, n_att, replace=False)\n",
        "    X_att[idx, :, axis] += drift_z\n",
        "    labels = np.zeros(N, dtype=int); labels[idx] = 1\n",
        "    return X_att, labels"
      ],
      "metadata": {
        "id": "Pbh0MIv2tq_m"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **Valutazione e visualizzazione**"
      ],
      "metadata": {
        "id": "BggHwxCCtxCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predizioni su test pulito\n",
        "def to_tensor(a): return torch.tensor(a, dtype=torch.float32)\n",
        "X_test_t = to_tensor(X_test)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_clean = model(X_test_t).numpy()\n",
        "err_clean = np.mean((pred_clean - y_test)**2, axis=1)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "def eval_attack(drift_m):\n",
        "    X_attack, labels = simulate_silent_drift(\n",
        "        X_test, std_x_m=STD_X_M, meters=drift_m, prob=ATTACK_PROB\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        pred_att = model(to_tensor(X_attack)).numpy()\n",
        "    err_att = np.mean((pred_att - y_test)**2, axis=1)\n",
        "    labels_all = np.concatenate([np.zeros_like(err_clean), labels])\n",
        "    scores_all = np.concatenate([err_clean, err_att])\n",
        "    auc  = roc_auc_score(labels_all, scores_all)\n",
        "    aupr = average_precision_score(labels_all, scores_all)\n",
        "    # plot veloce solo per l’ultimo run\n",
        "    plt.hist(err_clean, bins=50, alpha=0.6, label='normale')\n",
        "    plt.hist(err_att,   bins=50, alpha=0.6, label=f'spoofing {drift_m}m')\n",
        "    plt.title(\"Distribuzione errore di predizione (MSE)\")\n",
        "    plt.xlabel(\"Errore quadratico medio\"); plt.ylabel(\"Conteggio\"); plt.legend(); plt.show()\n",
        "    thr = np.percentile(err_clean, 99)   # soglia su clean (semplice)\n",
        "    tpr = float(np.mean(err_att > thr))\n",
        "    print(f\"Errore medio (clean={err_clean.mean():.5f}, attack={err_att.mean():.5f}) σ_clean={err_clean.std():.5f} σ_attack={err_att.std():.5f}\")\n",
        "    print(f\"Drift {drift_m} m → AUROC={auc:.3f}  AUPRC={aupr:.3f}  TPR@99p={tpr*100:.1f}%\")\n",
        "    return auc, aupr, tpr\n",
        "# --- Controllo STD ---\n",
        "if STD_X_M is None:\n",
        "    transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32616\", always_xy=True)\n",
        "    xs_m, ys_m = transformer.transform(df[\"LON\"].values, df[\"LAT\"].values)\n",
        "    STD_X_M = float(xs_m.std())\n",
        "    STD_Y_M = float(ys_m.std())\n",
        "    print(f\"[Auto-calibrato] STD_X_M={STD_X_M:.2f} m  STD_Y_M={STD_Y_M:.2f} m\")\n",
        "print(\"DEBUG STD:\", STD_X_M, STD_Y_M)\n",
        "if ATTACK_ENABLE:\n",
        "    if DRIFT_SWEEP_METERS:\n",
        "        results = []\n",
        "        for d in DRIFT_SWEEP_METERS:\n",
        "            results.append((d, *eval_attack(d)))\n",
        "        # tabellina risultati\n",
        "        print(\"\\n[Risultati sweep]\")\n",
        "        for d, auc, aupr, tpr in results:\n",
        "            print(f\"{d:>5} m  AUROC={auc:.3f}  AUPRC={aupr:.3f}  TPR@99p={tpr*100:.1f}%\")\n",
        "    else:\n",
        "        eval_attack(DRIFT_METERS)"
      ],
      "metadata": {
        "id": "Ulv20mCWtyO-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "5506fe28-12dc-4135-ef62-fa09bcdb9e4a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1291595030.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predizioni su test pulito\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_test_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyproj import Transformer\n",
        "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32616\", always_xy=True)\n",
        "xs_m, ys_m = transformer.transform(df[\"LON\"].values, df[\"LAT\"].values)\n",
        "print(xs_m.std(), ys_m.std())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DsrVur8Stem",
        "outputId": "6822169a-3bf5-46e2-dc2b-8020df05011c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33332.365630895016 33116.342012071436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output atteso**\n",
        "\n",
        "Grafico MSE: la curva “spoofing” sarà spostata a destra → errore maggiore.\n",
        "\n",
        "Tasso rilevamento: >90% con drift marcato."
      ],
      "metadata": {
        "id": "z6PqH9aetzoW"
      }
    }
  ]
}